{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b6d5d72",
   "metadata": {},
   "source": [
    "# 02-rag.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e10fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pypdf langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3416c",
   "metadata": {},
   "source": [
    "## 저장 파트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbaba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Document Load (PDF)\n",
    "# 지원하는 문서 로더: https://docs.langchain.com/oss/python/integrations/document_loaders\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 불러올 파일 위치\n",
    "file_path = './nke-10k-2023.pdf'\n",
    "\n",
    "# 대상 pdf 를 변환해줄 로더\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "# 로더가 pdf를 python에서 쓸 수 있도록 변환(pdf 1page -> 1 Document)\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))  # 원본 pdf 페이지수가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f903f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Splitting\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Document 를 잘라줄 스플리터\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "\n",
    "# 쪼개기\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(chunks))  # 전체 chunk 개수\n",
    "print(chunks[0].page_content)  # 첫번째 청크의 원본 텍스트 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Embedding (숫자로 바꾸기)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# 아래는 테스트용 (실제 텍스트 -> 벡터로 바뀌는 과정)\n",
    "v1 = embeddings.embed_query(chunks[0].page_content)  # 청크1 벡터로 변환\n",
    "v2 = embeddings.embed_query(chunks[1].page_content)  # 청크2 벡터로 변환\n",
    "\n",
    "# 차원수는 같아야 한다.\n",
    "print(len(v1) == len(v2))\n",
    "print(v1[:10])  # 벡터 눈으로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Vector Store 에 저장하기\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# 테스트/개발용 메모리 벡터스토어\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# pdf 쪼개놓은 chunks 를 벡터스토어에 저장 (저장 후 id들이 나옴)\n",
    "ids = vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e76c1",
   "metadata": {},
   "source": [
    "## 검색 파트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 -> 검색기로 활용\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type='similarity',  # 검색방식: 유사도\n",
    "    search_kwargs={'k': 3}     # 결과개수: 3개\n",
    ")\n",
    "\n",
    "# 검색\n",
    "retriever.invoke('나이키의 미국 영업점 개수?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86793e",
   "metadata": {},
   "source": [
    "## PDF RAG를 Agent 에 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기(retriever)를 Tool(함수)로 만들기\n",
    "\n",
    "# 검색어(query)를 인자로 받음\n",
    "def search_vectorstore(query: str) -> str:\n",
    "    \"\"\"Retrieve info to help answer a query about Nike\"\"\"\n",
    "    # 검색기 대신 벡터스토어 바로 활용하기 (chunk 2개만 검색)\n",
    "    docs = vector_store.similarity_search(query, k=2)\n",
    "    result = ''\n",
    "\n",
    "    for doc in docs:\n",
    "        result += doc.page_content + '\\n\\n'\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "print(search_vectorstore('나이키 영업점 개수'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd12e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "prompt = \"\"\"너는 2023 나이키 10k 보고서를 검색하는 도구를 다룰 수 있어. \n",
    "사용자 질문에 답변하기 위해 필요하면 사용해. 경제분석 전문가처럼 답변해.\"\"\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4.1-mini\",\n",
    "    tools=[search_vectorstore],\n",
    "    system_prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac5e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"나이키 영업점 숫자와 각 영업점 평균 매출액이 궁금함.\"\n",
    "\n",
    "agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e818da04",
   "metadata": {},
   "source": [
    "## Web문서(HTML) RAG + Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ead325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1980b6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 43047\n"
     ]
    }
   ],
   "source": [
    "# HTML은 문서 본문 외에 필요하지 않은 내용이 많다. 전처리가 필요하다!\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 전처리기\n",
    "bs4_strainer = bs4.SoupStrainer(class_=('post-title', 'post-header', 'post-content'))\n",
    "# 로더\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    bs_kwargs={'parse_only': bs4_strainer},  # 처리기 넣기\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "# 문서 페이지 수, 총 글자수\n",
    "print( len(docs), len(docs[0].page_content) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828262e1",
   "metadata": {},
   "source": [
    "### Todos\n",
    "1. Web Base Loader 로 불러온 docs Split\n",
    "2. Split 된 내용들을 OpenAI Embedding Model 을 활용하여 Vectorstore에 저장\n",
    "3. Agent 에 통합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4275aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(len(chunks))\n",
    "\n",
    "# Embedding\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# Store\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "ids = vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c631df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def search_vectorstore(query: str) -> str:\n",
    "    \"\"\"Retrieve info to help answer a user's query \"\"\"\n",
    "    docs = vector_store.similarity_search(query, k=4)\n",
    "    result = ''\n",
    "\n",
    "    for doc in docs:\n",
    "        result += doc.page_content + '\\n\\n'\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "prompt = \"\"\"사용자 질문에 답변하기 위한 검색하는 도구를 다룰 수 있어. \n",
    "사용자 질문에 답변하기 위해 사용해. 검색한 내용을 기반으로 답변해\"\"\"\n",
    "\n",
    "\n",
    "# Agent 에 통합하기\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4.1-mini\",\n",
    "    tools=[search_vectorstore],\n",
    "    system_prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d2be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='자율 Agent라는게 결국 무엇을 의미하는가', additional_kwargs={}, response_metadata={}, id='62891f02-fda0-40c6-a47d-57ee4aff020d'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 98, 'total_tokens': 116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_a391f2cee0', 'id': 'chatcmpl-DCh14AgEd8qy6fRRTfEIfSuUgdSLa', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c8e85-d94c-7da3-8a08-58ebfca9c6d9-0', tool_calls=[{'name': 'search_vectorstore', 'args': {'query': '자율 Agent 의미'}, 'id': 'call_2jG4PDGkdNKA1ZuV61es0qwx', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 98, 'output_tokens': 18, 'total_tokens': 116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nPseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\n\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\n', name='search_vectorstore', id='9bd6ae56-9bd8-4141-b018-fe61c63d8184', tool_call_id='call_2jG4PDGkdNKA1ZuV61es0qwx'),\n",
       "  AIMessage(content='자율 Agent란 스스로 목표를 설정하고, 상황을 인식하며, 계획을 수립하고, 실행하는 능력을 가진 소프트웨어 또는 시스템을 의미합니다. 즉, 외부의 직접적인 명령 없이 자율적으로 작업을 수행할 수 있는 지능형 에이전트라고 할 수 있습니다. 자율 Agent는 보통 인공지능 기술을 활용하여 환경과 상호작용하며, 문제 해결이나 의사결정을 스스로 수행합니다. \\n\\n필요시 추가 설명이나 구체적인 사례가 필요하면 말씀해 주세요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 547, 'total_tokens': 667, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_a391f2cee0', 'id': 'chatcmpl-DCh15EFduzPnWCsr8zZZPzsMSl3Lm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c8e85-dd22-7963-90bc-4fd0d481ef21-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 547, 'output_tokens': 120, 'total_tokens': 667, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"자율 Agent라는게 결국 무엇을 의미하는가\"\n",
    "\n",
    "agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
